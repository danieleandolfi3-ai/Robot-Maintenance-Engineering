{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "from numpy import quantile, where, random\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import max_error, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import warnings\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'C:/Users/gioca/GitHub/projects/maintenance_industry_4_2024/supporting_scripts/WP_4_20240528/')\n",
    "from utility import read_all_test_data_from_path, extract_selected_feature, prepare_sliding_window, FaultDetectReg, read_all_csvs_one_test, run_cv_one_motor, show_reg_result, show_clf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing definition (training)\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def compensate_seq_bias(df: pd.DataFrame):\n",
    "    ''' # Description\n",
    "    Adjust for the sequence-to-sequence bias.\n",
    "    '''\n",
    "    # Tranform the features relative to the first data point.\n",
    "    df['temperature'] = df['temperature'] - df['temperature'].iloc[0]\n",
    "    df['voltage'] = df['voltage'] - df['voltage'].iloc[0]\n",
    "    df['position'] = df['position'] - df['position'].iloc[0]\n",
    "\n",
    "# Function to design a Butterworth low-pass filter\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "# Function to apply the Butterworth low-pass filter\n",
    "def lowpass_filter(data, cutoff_freq, sampling_freq, order=5):\n",
    "    b, a = butter_lowpass(cutoff_freq, sampling_freq, order=order)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "# Set parameters for the low-pass filter\n",
    "cutoff_frequency = .5  # Adjust as needed\n",
    "sampling_frequency = 10  # Assuming your data is evenly spaced in time\n",
    "\n",
    "def customized_outlier_removal(df: pd.DataFrame):\n",
    "    ''' # Description\n",
    "    Remove outliers from the dataframe based on defined valid ranges. \n",
    "    Define a valid range of temperature and voltage. \n",
    "    Use ffil function to replace the invalid measurement with the previous value.\n",
    "    '''\n",
    "    df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "    df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "    df['position'] = df['position'].ffill()\n",
    "    df['position'] = lowpass_filter(df['position'], cutoff_frequency, sampling_frequency)\n",
    "    df['position'] = df['position'].rolling(window=10, min_periods=1).mean()\n",
    "    df['position'] = df['position'].round()\n",
    "\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "    df['temperature'] = df['temperature'].rolling(window=10, min_periods=1).mean()\n",
    "\n",
    "    # Make sure that the difference between the current and previous temperature cannot be too large.\n",
    "    # Define your threshold\n",
    "    threshold = 10\n",
    "    # Shift the 'temperature' column by one row to get the previous temperature\n",
    "    prev_tmp = df['temperature'].shift(1)\n",
    "    # Calculate the absolute difference between current and previous temperature\n",
    "    temp_diff = np.abs(df['temperature'] - prev_tmp)\n",
    "    # Set the temperature to NaN where the difference is larger than the threshold\n",
    "    df.loc[temp_diff > threshold, 'temperature'] = np.nan\n",
    "    df['temperature'] = df['temperature'].ffill()\n",
    "\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] <= 8000, np.nan)\n",
    "    df['voltage'] = df['voltage'].ffill()\n",
    "    df['voltage'] = lowpass_filter(df['voltage'], cutoff_frequency, sampling_frequency)\n",
    "    df['voltage'] = df['voltage'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' ### Description\n",
    "    Preprocess the data:\n",
    "    - remove outliers\n",
    "    - Adjust for the sequence-to-sequence bias.\n",
    "    - add new features about the difference between the current and previous n data point.\n",
    "    '''     \n",
    "    # Start processing.\n",
    "    customized_outlier_removal(df)\n",
    "    compensate_seq_bias(df)\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "base_dictionary = 'C:/Users/gioca/OneDrive - Politecnico di Milano/POLISSS/CentraleSupelec/Maintenance&I4.0/training_data/'\n",
    "\n",
    "# Get all the folders in the base_dictionary\n",
    "path_list = os.listdir(base_dictionary)\n",
    "# Only keep the folders, not the excel file.\n",
    "path_list = path_list[:-1]\n",
    "\n",
    "# Read the data.\n",
    "df_data_smooth = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    # Read the data with the customized outlier removal function.\n",
    "    tmp_df = read_all_csvs_one_test(path, tmp_path, pre_processing)\n",
    "    df_data_smooth = pd.concat([df_data_smooth, tmp_df])\n",
    "    df_data_smooth = df_data_smooth.reset_index(drop=True)\n",
    "\n",
    "# df_data_smooth_tr = df_data_smooth[df_data_smooth['test_condition'].isin(normal_test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading and pre-processing (training)\n",
    "\n",
    "# Read the data.\n",
    "df_tr = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    # Read the data with the customized outlier removal function.\n",
    "    tmp_df = read_all_csvs_one_test(path, tmp_path, customized_outlier_removal)\n",
    "    df_tr = pd.concat([df_tr, tmp_df])\n",
    "    df_tr = df_tr.reset_index(drop=True)\n",
    "\n",
    "conditions_path = r'C:/Users/gioca/OneDrive - Politecnico di Milano/POLISSS/CentraleSupelec/Maintenance&I4.0/training_data/Test conditions.xlsx'\n",
    "conditions = pd.read_excel(conditions_path)\n",
    "df_merged = df_tr.merge(conditions, how='left', left_on='test_condition', right_on='Test id')\n",
    "df_tr['operation'] = df_merged['Description']\n",
    "list_operations = pd.unique(conditions.Description).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing definition (testing)\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def compensate_seq_bias(df: pd.DataFrame):\n",
    "    ''' # Description\n",
    "    Adjust for the sequence-to-sequence bias.\n",
    "    '''\n",
    "    # Tranform the features relative to the first data point.\n",
    "    df['temperature'] = df['temperature'] - df['temperature'].iloc[0]\n",
    "    df['voltage'] = df['voltage'] - df['voltage'].iloc[0]\n",
    "    df['position'] = df['position'] - df['position'].iloc[0]\n",
    "\n",
    "# Function to design a Butterworth low-pass filter\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "# Function to apply the Butterworth low-pass filter\n",
    "def lowpass_filter(data, cutoff_freq, sampling_freq, order=5):\n",
    "    b, a = butter_lowpass(cutoff_freq, sampling_freq, order=order)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "# Set parameters for the low-pass filter\n",
    "cutoff_frequency = .5  # Adjust as needed\n",
    "sampling_frequency = 10  # Assuming your data is evenly spaced in time\n",
    "\n",
    "def customized_outlier_removal(df: pd.DataFrame):\n",
    "    ''' # Description\n",
    "    Remove outliers from the dataframe based on defined valid ranges. \n",
    "    Define a valid range of temperature and voltage. \n",
    "    Use ffil function to replace the invalid measurement with the previous value.\n",
    "    '''\n",
    "    df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "    df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "    df['position'] = df['position'].ffill()\n",
    "    df['position'] = lowpass_filter(df['position'], cutoff_frequency, sampling_frequency)\n",
    "    df['position'] = df['position'].rolling(window=10, min_periods=1).mean()\n",
    "    df['position'] = df['position'].round()\n",
    "\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "    df['temperature'] = df['temperature'].rolling(window=10, min_periods=1).mean()\n",
    "\n",
    "    # Make sure that the difference between the current and previous temperature cannot be too large.\n",
    "    # Define your threshold\n",
    "    threshold = 10\n",
    "    # Shift the 'temperature' column by one row to get the previous temperature\n",
    "    prev_tmp = df['temperature'].shift(1)\n",
    "    # Calculate the absolute difference between current and previous temperature\n",
    "    temp_diff = np.abs(df['temperature'] - prev_tmp)\n",
    "    # Set the temperature to NaN where the difference is larger than the threshold\n",
    "    df.loc[temp_diff > threshold, 'temperature'] = np.nan\n",
    "    df['temperature'] = df['temperature'].ffill()\n",
    "\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] <= 8000, np.nan)\n",
    "    df['voltage'] = df['voltage'].ffill()\n",
    "    df['voltage'] = lowpass_filter(df['voltage'], cutoff_frequency, sampling_frequency)\n",
    "    df['voltage'] = df['voltage'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' ### Description\n",
    "    Preprocess the data:\n",
    "    - remove outliers\n",
    "    - Adjust for the sequence-to-sequence bias.\n",
    "    - add new features about the difference between the current and previous n data point.\n",
    "    '''     \n",
    "    # Start processing.\n",
    "    customized_outlier_removal(df)\n",
    "    compensate_seq_bias(df)\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "base_dictionary = 'C:/Users/gioca/OneDrive - Politecnico di Milano/POLISSS/CentraleSupelec/Maintenance&I4.0/testing_data/'\n",
    "\n",
    "# Get all the folders in the base_dictionary\n",
    "path_list = os.listdir(base_dictionary)\n",
    "# Only keep the folders, not the excel file.\n",
    "path_list = path_list[:-1]\n",
    "\n",
    "# Read the data.\n",
    "df_data_smooth = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    # Read the data with the customized outlier removal function.\n",
    "    tmp_df = read_all_csvs_one_test(path, tmp_path, pre_processing)\n",
    "    df_data_smooth = pd.concat([df_data_smooth, tmp_df])\n",
    "    df_data_smooth = df_data_smooth.reset_index(drop=True)\n",
    "\n",
    "# df_data_smooth_tr = df_data_smooth[df_data_smooth['test_condition'].isin(normal_test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading and pre-processing (test)\n",
    "\n",
    "# Read the data.\n",
    "\n",
    "df_te = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    # Read the data with the customized outlier removal function.\n",
    "    tmp_df_test = read_all_csvs_one_test(path, tmp_path, customized_outlier_removal)\n",
    "    df_te = pd.concat([df_te, tmp_df_test])\n",
    "    df_te = df_te.reset_index(drop=True)\n",
    "\n",
    "conditions_path = r'C:/Users/gioca/OneDrive - Politecnico di Milano/POLISSS/CentraleSupelec/Maintenance&I4.0/testing_data/Test conditions.xlsx'\n",
    "conditions = pd.read_excel(conditions_path)\n",
    "df_merged = df_te.merge(conditions, how='left', left_on='test_condition', right_on='Test id')\n",
    "df_te['operation'] = df_merged['Description']\n",
    "list_operations = pd.unique(conditions.Description).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_test_conditions_for_motor_x(dataset, motor_number):\n",
    "    \"\"\"\n",
    "    Trova le condizioni di test per le quali, riducendo il dataset, compare almeno un data_motor_x_label = 1.\n",
    "    \n",
    "    Args:\n",
    "    - dataset (pd.DataFrame): Il dataset da analizzare.\n",
    "    - motor_number (int): Il numero del motore da considerare.\n",
    "    \n",
    "    Returns:\n",
    "    - List: Lista delle test_condition che soddisfano il criterio.\n",
    "    \"\"\"\n",
    "    # Nome della colonna da cercare\n",
    "    target_column = f'data_motor_{motor_number}_label'\n",
    "    \n",
    "    # Trova tutte le condizioni di test uniche\n",
    "    test_conditions = dataset['test_condition'].unique()\n",
    "    \n",
    "    # Lista per memorizzare le condizioni di test valide\n",
    "    valid_conditions = []\n",
    "    \n",
    "    # Verifica ogni condizione di test\n",
    "    for condition in test_conditions:\n",
    "        # Filtra il dataset per la condizione di test corrente\n",
    "        filtered_dataset = dataset[dataset['test_condition'] == condition]\n",
    "        \n",
    "        # Verifica se esiste almeno una riga con data_motor_x_label = 1\n",
    "        if (filtered_dataset[target_column] == 1).any():\n",
    "            valid_conditions.append(condition)\n",
    "    \n",
    "    return valid_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gioca\\OneDrive - Politecnico di Milano\\POLISSS\\CentraleSupelec\\Maintenance&I4.0\\Group_6\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from utility import extract_selected_feature, prepare_sliding_window\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the motor index.\n",
    "motor_idx = 3\n",
    "\n",
    "valid_conditions = find_test_conditions_for_motor_x(df_tr, motor_idx)\n",
    "    \n",
    "# Filtra il DataFrame originale usando le condizioni di test valide\n",
    "df_train = df_tr[df_tr['test_condition'].isin(valid_conditions)]\n",
    "\n",
    "# Define the features.\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "# Extract the features.\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_train, feature_list_all, motor_idx, mdl_type='clf')\n",
    "\n",
    "# Prepare the training data based on the defined sliding window.\n",
    "window_size = 1\n",
    "sample_step = 1\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "# Define the classification model.\n",
    "# Define the steps of the pipeline\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('mdl', LogisticRegression(class_weight='balanced'))    # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'mdl__C': [0.001, 0.01, 0.1, 1, 10, 100]  # Inverse of regularization strength\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1', cv=5)\n",
    "\n",
    "# Train the model.\n",
    "mdl = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for the testing dataset.\n",
    "# Define the features.\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage',\n",
    "                    'data_motor_2_position', 'data_motor_2_temperature', 'data_motor_2_voltage',\n",
    "                    'data_motor_3_position', 'data_motor_3_temperature', 'data_motor_3_voltage',\n",
    "                    'data_motor_4_position', 'data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_5_voltage',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "# Add test_condition for extracting different sequences.\n",
    "feature_list_all.append('test_condition')\n",
    "# Get the features.\n",
    "df_test_x = df_te[feature_list_all]\n",
    "# Augument the features in the same way as the training data.\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "# Make prediction.\n",
    "y_pred_3 = grid_search.predict(X_test)\n",
    "\n",
    "df_pred = pd.DataFrame({\n",
    "    'time': df_te['time'],\n",
    "    'test_condition': df_te['test_condition']\n",
    "})\n",
    "\n",
    "for x in range(1, 7):\n",
    "    df_pred[f'data_motor_{x}_label'] = -1\n",
    "\n",
    "# Inserimento dei valori di y_pred nella colonna data_motor_3_label\n",
    "df_pred['data_motor_3_label'] = y_pred_3\n",
    "df_pred.reset_index(inplace=True)\n",
    "df_pred.rename(columns={'index': 'idx'}, inplace=True)\n",
    "\n",
    "df_pred.to_csv('df_pred_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor  1\n",
      "Results for test condition 20240325_155003:\n",
      "Accuracy: 0.80\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240426_140055:\n",
      "Accuracy: 0.95\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240524_094877:\n",
      "Accuracy: 0.67\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240524_100052:\n",
      "Accuracy: 0.80\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240524_110994:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Motor  2\n",
      "Results for test condition 20240325_155003:\n",
      "Accuracy: 0.14\n",
      "Precision: 1.00\n",
      "Recall: 0.14\n",
      "F1 Score: 0.25\n",
      "\n",
      "Results for test condition 20240426_140055:\n",
      "Accuracy: 0.94\n",
      "Precision: 1.00\n",
      "Recall: 0.23\n",
      "F1 Score: 0.37\n",
      "\n",
      "Results for test condition 20240524_110994:\n",
      "Accuracy: 0.20\n",
      "Precision: 0.07\n",
      "Recall: 0.93\n",
      "F1 Score: 0.13\n",
      "\n",
      "Motor  3\n",
      "Results for test condition 20240325_155003:\n",
      "Accuracy: 0.99\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240426_140055:\n",
      "Accuracy: 0.08\n",
      "Precision: 0.08\n",
      "Recall: 0.95\n",
      "F1 Score: 0.14\n",
      "\n",
      "Results for test condition 20240524_110994:\n",
      "Accuracy: 0.91\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Motor  4\n",
      "Results for test condition 20240325_155003:\n",
      "Accuracy: 0.00\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240426_140055:\n",
      "Accuracy: 0.92\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240524_110994:\n",
      "Accuracy: 0.17\n",
      "Precision: 0.17\n",
      "Recall: 1.00\n",
      "F1 Score: 0.28\n",
      "\n",
      "Motor  5\n",
      "Results for test condition 20240325_155003:\n",
      "Accuracy: 0.95\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240426_140055:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240524_110994:\n",
      "Accuracy: 0.85\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Motor  6\n",
      "Results for test condition 20240325_155003:\n",
      "Accuracy: 0.77\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240425_093699:\n",
      "Accuracy: 0.65\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240425_094425:\n",
      "Accuracy: 0.77\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240426_140055:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240503_163963:\n",
      "Accuracy: 0.70\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240503_164675:\n",
      "Accuracy: 0.20\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240503_165189:\n",
      "Accuracy: 0.73\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n",
      "Results for test condition 20240524_110994:\n",
      "Accuracy: 0.88\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on the training dataset\n",
    "\n",
    "models = []\n",
    "\n",
    "for motor_number in range(1, 6+1):\n",
    "\n",
    "    print(\"Motor \", motor_number)\n",
    "\n",
    "    # Trova le condizioni di test valide per il motore corrente\n",
    "    valid_conditions = find_test_conditions_for_motor_x(df, motor_number)\n",
    "    \n",
    "    # Filtra il DataFrame originale usando le condizioni di test valide\n",
    "    df_tr_x = df[df['test_condition'].isin(valid_conditions)]\n",
    "\n",
    "    # Initialize rf model\n",
    "\n",
    "    rf_model = LogisticRegression()\n",
    "    results = []\n",
    "\n",
    "    for condition in valid_conditions:\n",
    "        # Dividi il dataset in test e training\n",
    "        df_train = df_tr_x[df_tr_x['test_condition'] != condition]\n",
    "        df_test = df_tr_x[df_tr_x['test_condition'] == condition]\n",
    "    \n",
    "        X_train = df_train[[f'data_motor_{motor_number}_position', f'data_motor_{motor_number}_temperature', f'data_motor_{motor_number}_voltage']]\n",
    "        y_train = df_train[[f'data_motor_{motor_number}_label']]\n",
    "        y_train = y_train[f'data_motor_{motor_number}_label']\n",
    "    \n",
    "        X_test = df_test[[f'data_motor_{motor_number}_position', f'data_motor_{motor_number}_temperature', f'data_motor_{motor_number}_voltage']]\n",
    "        y_test = df_test[[f'data_motor_{motor_number}_label']]\n",
    "        y_test = y_test[f'data_motor_{motor_number}_label']\n",
    "    \n",
    "        # Addestra il modello sui dati di training\n",
    "        rf_model.fit(X_train, y_train)\n",
    "    \n",
    "        # Fai previsioni sui dati di test\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "        # Calcola le metriche\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "        # Memorizza i risultati\n",
    "        results.append({\n",
    "            'condition': condition,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        })\n",
    "    \n",
    "        # Stampa i risultati per ogni condizione\n",
    "        print(f\"Results for test condition {condition}:\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        print(f\"Recall: {recall:.2f}\")\n",
    "        print(f\"F1 Score: {f1:.2f}\")\n",
    "        print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
